# -*- coding: utf-8 -*-
"""lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OsORxcGu_tQuthHR1JJI4aH5YY2001JP
"""

from collections import defaultdict
from pathlib import Path

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import math
# # Commented out IPython magic to ensure Python compatibility.
# from __future__ import absolute_import, division, print_function, unicode_literals
# %tensorflow_version 2.x

import tensorflow as tf

tf.compat.v1.enable_eager_execution()
print(tf.executing_eagerly())
print(tf.__version__)

"""# Download dataset"""

# Download the dataset data
# !wget -nc http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz
#
# # Uncompress files
# if not os.path.exists("./CUB_200_2011"):
#   !tar xvzf CUB_200_2011.tgz
# else:
#   print("Dataset already uncompressed")

"""## Load classification dataset to a Pandas DataFrame"""

PATH = Path('./CUB_200_2011')
images_path = PATH / "images/"
# Load image labels, training/test label and file path. 
train_labels = pd.read_csv(PATH / "image_class_labels.txt", header=None, sep=" ",
                           index_col=0, names=["class_label"])
train_test = pd.read_csv(PATH / "train_test_split.txt", header=None, sep=" ",
                         index_col=0, names=["is_train"])
images = pd.read_csv(PATH / "images.txt", header=None, sep=" ", index_col=0,
                     names=["img_path"])
images = images.apply(lambda x: "./CUB_200_2011/images/" + x)
# Combine dataset into single Pandas DataFrame 
# image ID is the index of the dataset DataFrame 
dataset = pd.concat((train_labels, train_test, images), axis=1)

train_data = dataset[dataset["is_train"] == 1]
test_data = dataset[dataset["is_train"] == 0]

"""## Create tf.data.Dataset from images and labels for testing and training"""

IMG_HEIGHT = 128
IMG_WIDTH = 128
N_CHANNELS = 3
N_CLASSES = 200
N_IMAGES =len(dataset)


def get_mean_std(train_data, test_data):
    mean = defaultdict(int)
    stddev = defaultdict(int)
    # std_train_list = []
    # train_set = {}
    for count, img_tensor in enumerate(train_data["img_path"]):
        img = cv2.imread(img_tensor) / 255.0
        img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))
        means, _ = cv2.meanStdDev(img)
        mean['R'] += means[0][0]
        mean['G'] += means[1][0]
        mean['B'] += means[2][0]
        # std_train_list.append(stddev)
        # train_set[count] = (img)

    # std_test_list = []
    # test_set = {}
    for count, img_tensor in enumerate(test_data["img_path"]):
        img = cv2.imread(img_tensor).astype(np.float32) / 255.0
        img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))
        means, _ = cv2.meanStdDev(img)
        mean['R'] += means[0][0]
        mean['G'] += means[1][0]
        mean['B'] += means[2][0]

        # std_test_list.append(stddev)
        # test_set[count] = img

    for item, value in mean.items():
        mean[item] = value / float(N_IMAGES)

    for count, img_tensor in enumerate(train_data["img_path"]):
        img = cv2.imread(img_tensor).astype(np.float32) / 255.0
        img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))
        # sum((x - mean(x)). ^ 2) / (length(x) - 1);
        stddev['R'] += np.sum(np.power(img[:, :, 0] - mean['R'], 2) / (IMG_HEIGHT * IMG_WIDTH - 1))
        stddev['G'] += np.sum((np.power(img[:, :, 1] - mean['G'], 2))) / (IMG_HEIGHT * IMG_WIDTH - 1)
        stddev['B'] += np.sum((np.power(img[:, :, 2] - mean['B'], 2))) / (IMG_HEIGHT * IMG_WIDTH - 1)

    for item, value in stddev.items():
        stddev[item] = value / float(N_IMAGES)

    print("The mean Red value is %3f" % mean['R'])
    print("The mean Green value is %3f" % mean['G'])
    print("The mean Blue value is %3f" % mean['B'])
    print(mean.values())

    print("The std Red value is %3f" % stddev['R'])
    print("The std Green value is %3f" % stddev['G'])
    print("The std Blue value is %3f" % stddev['B'])
    print(stddev.values())
    return mean.values, stddev.values


mean, stddev = get_mean_std(train_data, test_data)

print("Training dataset contains %d images" % train_data.shape[0])
# display(train_data.sample(5))
print("Test dataset contains %d images" % test_data.shape[0])
# display(test_data.sample(5))

classes = pd.read_csv(PATH / "classes.txt", header=None, sep=" ", index_col=0,
                      names=["class"])


def get_class_name(class_id):
    return classes.iloc[class_id]["class"]


get_class_name(100)
classes.head(10)


def get_img(img_path):
    img = tf.io.read_file(img_path)
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_jpeg(img, channels=3)
    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, dtype=tf.float32)

    # resize the image to the desired size.
    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])


    _, stddevs = tf.nn.moments(img, axes=[0, 1])
    # stddevs = []
    # stddevs.append(tf.math.reduce_std(
    #     img, axis=0, keepdims=False, name=None
    # ))
    # stddevs.append(tf.math.reduce_std(
    #     img, axis=1, keepdims=False, name=None
    # ))
    # stddevs.append(tf.math.reduce_std(
    #     img, axis=2, keepdims=False, name=None
    # ))

    channel_r = (img[:, :, 0:1] - mean['R']) / stddevs[0]
    channel_g = (img[:, :, 1:2] - mean['G']) / stddevs[1]
    channel_b = (img[:, :, 2:3] - mean['B']) / stddevs[2]

    return tf.concat(axis=2, values=[channel_r, channel_g, channel_b])
    #
    # img_r = (img.numpy()[:, :, 0] - mean['R']) / stddevs[0]
    # img_g = (img.numpy()[:, :, 1] - mean['G']) / stddevs[1]
    # img_b = (img.numpy()[:, :, 2] - mean['B']) / stddevs[2]
    # return tf.convert_to_tensor([np.dstack((img_r, img_g, img_b))])


def show_batch(image_batch, label_batch):
    plt.figure(figsize=(15, 15))
    try:
        for n in range(25):
            ax = plt.subplot(5, 5, n+1)

            plt.imshow((image_batch[n]*255.0).astype(np.uint8))
            plt.title(get_class_name(np.argmax(label_batch[n])))
            plt.axis('off')
        plt.show()
    except Exception:
        pass



def get_tf_dataset(data, batch_size=32):
    global final_dataset
    imagepaths = tf.convert_to_tensor(data['img_path'].values, dtype=tf.string)
    labels = tf.convert_to_tensor(data['class_label'].values, dtype=tf.int32)

    dataset = tf.data.Dataset.from_tensor_slices((imagepaths, labels - 1))
    dataset = dataset.shuffle(4000)

    dataset = dataset.map(lambda img_path, label: (get_img(img_path), label))


    dataset = dataset.batch(batch_size=batch_size)

    return dataset


# Get tf.data.Datasets objects
train_dataset = get_tf_dataset(train_data, batch_size=32)



# Show a training
image_batch, label_batch = next(iter(train_dataset))
show_batch(image_batch.numpy(), label_batch.numpy())

print("Image batch has shape: ", image_batch.numpy().shape)
print("Image label has shape: ", label_batch.numpy().shape)

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, N_CHANNELS)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(100, activation='relu'),
  tf.keras.layers.Dense(N_CLASSES, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()
history = model.fit(train_dataset, epochs=4)

test_dataset = get_tf_dataset(test_data, batch_size=32)

test_loss = model.evaluate(test_dataset)

print(test_loss)
# tf.one_hot(10, 200)
